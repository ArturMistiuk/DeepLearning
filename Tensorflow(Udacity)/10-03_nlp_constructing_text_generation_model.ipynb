{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "9b3a7a8c-f857-406d-8098-94d538259842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-24 14:01:40--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.137.101, 74.125.137.138, 74.125.137.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.137.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "--2025-05-24 14:01:40--  https://drive.usercontent.google.com/download?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  80.4MB/s    in 0.9s    \n",
            "\n",
            "2025-05-24 14:01:45 (80.4 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "apcEXp7WhVBs",
        "outputId": "52b9f766-a191-4665-8ae0-b28735ba6e81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'a': 2, 'i': 3, 'and': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'be': 10, 'ma': 11, 'it': 12, 'of': 13, \"i'm\": 14, 'your': 15, 'love': 16, 'so': 17, 'as': 18, 'boomerang': 19, 'that': 20, 'in': 21, 'andante': 22, 'boom': 23, 'make': 24, 'dumb': 25, 'on': 26, 'oh': 27, 'dum': 28, 'for': 29, 'but': 30, 'new': 31, 'bang': 32, \"it's\": 33, 'like': 34, 'know': 35, 'now': 36, 'how': 37, 'could': 38, \"you're\": 39, 'sing': 40, 'never': 41, 'no': 42, 'hum': 43, 'chiquitita': 44, 'can': 45, 'we': 46, 'song': 47, 'had': 48, 'good': 49, \"you'll\": 50, 'she': 51, 'just': 52, 'girl': 53, 'again': 54, 'will': 55, 'take': 56, 'please': 57, 'let': 58, 'am': 59, 'eyes': 60, 'was': 61, 'always': 62, 'cassandra': 63, 'blue': 64, 'time': 65, \"don't\": 66, 'were': 67, 'return': 68, 'once': 69, 'then': 70, 'sorry': 71, \"cryin'\": 72, 'over': 73, 'feel': 74, 'ever': 75, 'believe': 76, 'what': 77, 'do': 78, 'go': 79, 'all': 80, 'out': 81, 'think': 82, 'every': 83, 'leave': 84, 'look': 85, 'at': 86, 'way': 87, 'one': 88, 'music': 89, 'down': 90, 'our': 91, 'give': 92, 'learn': 93, 'more': 94, 'us': 95, 'would': 96, 'there': 97, 'before': 98, 'when': 99, 'with': 100, 'feeling': 101, 'play': 102, \"'cause\": 103, 'away': 104, 'here': 105, 'have': 106, 'yes': 107, 'baby': 108, 'get': 109, \"didn't\": 110, 'see': 111, 'did': 112, 'closed': 113, 'realized': 114, 'crazy': 115, 'world': 116, 'lord': 117, \"she's\": 118, 'kind': 119, 'without': 120, 'if': 121, 'touch': 122, 'strong': 123, 'making': 124, 'such': 125, 'found': 126, 'true': 127, 'stay': 128, 'together': 129, 'thought': 130, 'come': 131, 'they': 132, 'sweet': 133, 'tender': 134, 'sender': 135, 'tune': 136, 'de': 137, 'gonna': 138, 'last': 139, 'leaving': 140, 'sleep': 141, 'only': 142, 'saw': 143, 'tell': 144, \"he's\": 145, 'her': 146, 'sound': 147, 'tread': 148, 'lightly': 149, 'ground': 150, \"i'll\": 151, 'show': 152, 'life': 153, 'too': 154, 'used': 155, 'darling': 156, 'meant': 157, 'break': 158, 'end': 159, 'yourself': 160, 'little': 161, \"you've\": 162, 'by': 163, \"they're\": 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'about': 207, 'things': 208, 'slow': 209, \"there's\": 210, 'talk': 211, 'why': 212, 'up': 213, 'lousy': 214, 'packing': 215, \"i've\": 216, 'gotta': 217, 'near': 218, 'keeping': 219, 'intention': 220, 'growing': 221, 'taking': 222, 'dimension': 223, 'even': 224, 'better': 225, 'thank': 226, 'god': 227, 'not': 228, 'somebody': 229, 'happy': 230, 'question': 231, 'smile': 232, 'mean': 233, 'much': 234, 'kisses': 235, 'around': 236, 'anywhere': 237, 'advice': 238, 'care': 239, 'use': 240, 'selfish': 241, 'tool': 242, 'fool': 243, 'showing': 244, 'throwing': 245, 'warm': 246, 'kiss': 247, 'surrender': 248, 'giving': 249, 'been': 250, 'door': 251, 'burning': 252, 'bridges': 253, 'being': 254, 'moving': 255, 'though': 256, 'behind': 257, 'are': 258, 'must': 259, 'sure': 260, 'stood': 261, 'hope': 262, 'this': 263, 'deny': 264, 'sad': 265, 'quiet': 266, 'truth': 267, 'heartaches': 268, 'scars': 269, 'dancing': 270, 'sky': 271, 'shining': 272, 'above': 273, 'hear': 274, 'came': 275, \"couldn't\": 276, 'everything': 277, 'back': 278, 'long': 279, \"waitin'\": 280, 'cold': 281, 'chills': 282, 'bone': 283, \"you'd\": 284, 'wonderful': 285, 'means': 286, 'special': 287, 'smiles': 288, 'lucky': 289, 'fellow': 290, 'park': 291, 'holds': 292, 'squeezes': 293, \"we'll\": 294, 'walking': 295, 'hours': 296, 'talking': 297, 'plan': 298, 'easy': 299, 'gently': 300, 'summer': 301, 'evening': 302, 'breeze': 303, 'grow': 304, 'fingers': 305, 'soft': 306, 'light': 307, 'body': 308, 'velvet': 309, 'night': 310, 'soul': 311, 'slowly': 312, 'shimmer': 313, 'thousand': 314, 'butterflies': 315, 'float': 316, 'put': 317, 'rotten': 318, 'boy': 319, 'tough': 320, 'stuff': 321, 'saying': 322, 'need': 323, 'anymore': 324, 'enough': 325, 'standing': 326, 'creep': 327, 'felt': 328, 'cheap': 329, 'notion': 330, 'deep': 331, 'mistake': 332, 'entitled': 333, 'another': 334, 'beg': 335, 'forgive': 336, 'an': 337, 'feels': 338, 'well': 339, 'hoot': 340, 'holler': 341, 'mad': 342, 'under': 343, 'heel': 344, 'holy': 345, 'christ': 346, 'deal': 347, 'sick': 348, 'tired': 349, 'tedious': 350, 'ways': 351, \"ain't\": 352, \"walkin'\": 353, 'cutting': 354, 'tie': 355, 'wanna': 356, 'into': 357, 'eye': 358, 'myself': 359, 'counting': 360, 'pride': 361, 'un': 362, 'right': 363, \"neighbour's\": 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, \"what's\": 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, \"love's\": 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, \"i'd\": 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, \"life's\": 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, \"sittin'\": 493, 'memories': 494}\n",
            "495\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_labels"
      ],
      "metadata": {
        "id": "r2HIW_hhoVri",
        "outputId": "163a968f-4c21-4ad1-d0fe-20f93fc96a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zsmu3aEId49i",
        "outputId": "f3434282-ddf3-4d3e-8dc7-511a1f19cbe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "101\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  85  86 146 197  33\n",
            "   2]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  85  86 146 197  33   2\n",
            " 285]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G1YXuxIqfygN",
        "outputId": "9f229e85-22d4-4cd8-a34f-616e5036d46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.0277 - loss: 6.0879\n",
            "Epoch 2/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0417 - loss: 5.4002\n",
            "Epoch 3/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0476 - loss: 5.3371\n",
            "Epoch 4/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0461 - loss: 5.1887\n",
            "Epoch 5/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0519 - loss: 5.1843\n",
            "Epoch 6/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0490 - loss: 5.1160\n",
            "Epoch 7/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0512 - loss: 5.0370\n",
            "Epoch 8/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0583 - loss: 4.9809\n",
            "Epoch 9/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0696 - loss: 4.8703\n",
            "Epoch 10/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0781 - loss: 4.7769\n",
            "Epoch 11/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0857 - loss: 4.7338\n",
            "Epoch 12/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1007 - loss: 4.6592\n",
            "Epoch 13/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1319 - loss: 4.5408\n",
            "Epoch 14/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1411 - loss: 4.4848\n",
            "Epoch 15/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1590 - loss: 4.4075\n",
            "Epoch 16/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1659 - loss: 4.3671\n",
            "Epoch 17/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1663 - loss: 4.2630\n",
            "Epoch 18/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1953 - loss: 4.1264\n",
            "Epoch 19/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.1944 - loss: 4.0536\n",
            "Epoch 20/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2095 - loss: 3.9300\n",
            "Epoch 21/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2143 - loss: 3.8813\n",
            "Epoch 22/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2423 - loss: 3.7303\n",
            "Epoch 23/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2584 - loss: 3.5825\n",
            "Epoch 24/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2748 - loss: 3.5289\n",
            "Epoch 25/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2900 - loss: 3.4864\n",
            "Epoch 26/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3040 - loss: 3.4100\n",
            "Epoch 27/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3059 - loss: 3.3826\n",
            "Epoch 28/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3334 - loss: 3.2385\n",
            "Epoch 29/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.3507 - loss: 3.1810\n",
            "Epoch 30/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.3700 - loss: 3.1111\n",
            "Epoch 31/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.3999 - loss: 2.9839\n",
            "Epoch 32/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3948 - loss: 2.9631\n",
            "Epoch 33/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4264 - loss: 2.8917\n",
            "Epoch 34/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4275 - loss: 2.8168\n",
            "Epoch 35/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4381 - loss: 2.8133\n",
            "Epoch 36/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4522 - loss: 2.7399\n",
            "Epoch 37/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4652 - loss: 2.6596\n",
            "Epoch 38/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4778 - loss: 2.5948\n",
            "Epoch 39/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4956 - loss: 2.5650\n",
            "Epoch 40/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4755 - loss: 2.5958\n",
            "Epoch 41/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5118 - loss: 2.4553\n",
            "Epoch 42/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5234 - loss: 2.3930\n",
            "Epoch 43/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5210 - loss: 2.3504\n",
            "Epoch 44/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5338 - loss: 2.3101\n",
            "Epoch 45/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5557 - loss: 2.2310\n",
            "Epoch 46/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5376 - loss: 2.2620\n",
            "Epoch 47/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5515 - loss: 2.2487\n",
            "Epoch 48/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5669 - loss: 2.1703\n",
            "Epoch 49/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5824 - loss: 2.0852\n",
            "Epoch 50/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5895 - loss: 2.0385\n",
            "Epoch 51/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5898 - loss: 2.0666\n",
            "Epoch 52/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6106 - loss: 1.9583\n",
            "Epoch 53/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6238 - loss: 1.9139\n",
            "Epoch 54/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6074 - loss: 1.9374\n",
            "Epoch 55/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6289 - loss: 1.8936\n",
            "Epoch 56/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6162 - loss: 1.8720\n",
            "Epoch 57/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6292 - loss: 1.8636\n",
            "Epoch 58/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6357 - loss: 1.8248\n",
            "Epoch 59/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6449 - loss: 1.7922\n",
            "Epoch 60/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6660 - loss: 1.7113\n",
            "Epoch 61/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6637 - loss: 1.6965\n",
            "Epoch 62/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6816 - loss: 1.6405\n",
            "Epoch 63/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6739 - loss: 1.6189\n",
            "Epoch 64/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6839 - loss: 1.6043\n",
            "Epoch 65/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7050 - loss: 1.5385\n",
            "Epoch 66/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6998 - loss: 1.5269\n",
            "Epoch 67/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6901 - loss: 1.5401\n",
            "Epoch 68/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7049 - loss: 1.4457\n",
            "Epoch 69/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7131 - loss: 1.4495\n",
            "Epoch 70/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7027 - loss: 1.4734\n",
            "Epoch 71/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7200 - loss: 1.4213\n",
            "Epoch 72/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7256 - loss: 1.3957\n",
            "Epoch 73/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 1.3962\n",
            "Epoch 74/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7276 - loss: 1.3225\n",
            "Epoch 75/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7291 - loss: 1.3310\n",
            "Epoch 76/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7277 - loss: 1.3251\n",
            "Epoch 77/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7417 - loss: 1.2969\n",
            "Epoch 78/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7314 - loss: 1.3204\n",
            "Epoch 79/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7253 - loss: 1.2880\n",
            "Epoch 80/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7454 - loss: 1.2567\n",
            "Epoch 81/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7353 - loss: 1.2439\n",
            "Epoch 82/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7636 - loss: 1.2007\n",
            "Epoch 83/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7584 - loss: 1.1962\n",
            "Epoch 84/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7774 - loss: 1.1306\n",
            "Epoch 85/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7678 - loss: 1.1247\n",
            "Epoch 86/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7560 - loss: 1.1709\n",
            "Epoch 87/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7958 - loss: 1.0779\n",
            "Epoch 88/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7943 - loss: 1.0581\n",
            "Epoch 89/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7958 - loss: 1.0527\n",
            "Epoch 90/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8045 - loss: 1.0196\n",
            "Epoch 91/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8121 - loss: 0.9957\n",
            "Epoch 92/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7904 - loss: 1.0805\n",
            "Epoch 93/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8087 - loss: 0.9820\n",
            "Epoch 94/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8212 - loss: 0.9375\n",
            "Epoch 95/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7860 - loss: 1.0607\n",
            "Epoch 96/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7940 - loss: 1.0222\n",
            "Epoch 97/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7959 - loss: 0.9900\n",
            "Epoch 98/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8129 - loss: 0.9749\n",
            "Epoch 99/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8229 - loss: 0.8937\n",
            "Epoch 100/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8047 - loss: 0.9522\n",
            "Epoch 101/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8262 - loss: 0.9008\n",
            "Epoch 102/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8130 - loss: 0.9043\n",
            "Epoch 103/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8261 - loss: 0.8764\n",
            "Epoch 104/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.8813\n",
            "Epoch 105/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 0.8102\n",
            "Epoch 106/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8379 - loss: 0.8217\n",
            "Epoch 107/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8388 - loss: 0.8113\n",
            "Epoch 108/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8465 - loss: 0.8045\n",
            "Epoch 109/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8391 - loss: 0.8280\n",
            "Epoch 110/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8390 - loss: 0.7926\n",
            "Epoch 111/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8368 - loss: 0.8124\n",
            "Epoch 112/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8381 - loss: 0.8074\n",
            "Epoch 113/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8367 - loss: 0.7849\n",
            "Epoch 114/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8323 - loss: 0.7861\n",
            "Epoch 115/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8341 - loss: 0.7550\n",
            "Epoch 116/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.7568\n",
            "Epoch 117/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8459 - loss: 0.7463\n",
            "Epoch 118/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8422 - loss: 0.7527\n",
            "Epoch 119/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8576 - loss: 0.7244\n",
            "Epoch 120/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8635 - loss: 0.6874\n",
            "Epoch 121/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8624 - loss: 0.7029\n",
            "Epoch 122/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8568 - loss: 0.6982\n",
            "Epoch 123/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8420 - loss: 0.7066\n",
            "Epoch 124/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8526 - loss: 0.7024\n",
            "Epoch 125/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.6861\n",
            "Epoch 126/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8436 - loss: 0.6992\n",
            "Epoch 127/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.6360\n",
            "Epoch 128/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8653 - loss: 0.6288\n",
            "Epoch 129/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8678 - loss: 0.6484\n",
            "Epoch 130/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8723 - loss: 0.6408\n",
            "Epoch 131/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8664 - loss: 0.6266\n",
            "Epoch 132/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.6395\n",
            "Epoch 133/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.6472\n",
            "Epoch 134/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8793 - loss: 0.5978\n",
            "Epoch 135/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8706 - loss: 0.5855\n",
            "Epoch 136/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8730 - loss: 0.6076\n",
            "Epoch 137/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8805 - loss: 0.5946\n",
            "Epoch 138/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 0.5784\n",
            "Epoch 139/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.6047\n",
            "Epoch 140/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.6006\n",
            "Epoch 141/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8787 - loss: 0.5560\n",
            "Epoch 142/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8715 - loss: 0.5853\n",
            "Epoch 143/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8720 - loss: 0.5739\n",
            "Epoch 144/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8784 - loss: 0.5483\n",
            "Epoch 145/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8717 - loss: 0.5577\n",
            "Epoch 146/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8684 - loss: 0.5562\n",
            "Epoch 147/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8829 - loss: 0.5445\n",
            "Epoch 148/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.5245\n",
            "Epoch 149/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8815 - loss: 0.5099\n",
            "Epoch 150/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8840 - loss: 0.5166\n",
            "Epoch 151/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8678 - loss: 0.5339\n",
            "Epoch 152/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8644 - loss: 0.5655\n",
            "Epoch 153/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8815 - loss: 0.5284\n",
            "Epoch 154/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8776 - loss: 0.5095\n",
            "Epoch 155/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8839 - loss: 0.4981\n",
            "Epoch 156/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8823 - loss: 0.5072\n",
            "Epoch 157/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8807 - loss: 0.4948\n",
            "Epoch 158/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8822 - loss: 0.4826\n",
            "Epoch 159/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.4988\n",
            "Epoch 160/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.4844\n",
            "Epoch 161/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8757 - loss: 0.4784\n",
            "Epoch 162/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8792 - loss: 0.4803\n",
            "Epoch 163/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.4524\n",
            "Epoch 164/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8938 - loss: 0.4355\n",
            "Epoch 165/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8842 - loss: 0.4610\n",
            "Epoch 166/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8995 - loss: 0.4391\n",
            "Epoch 167/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8809 - loss: 0.4668\n",
            "Epoch 168/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8841 - loss: 0.4681\n",
            "Epoch 169/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8959 - loss: 0.4300\n",
            "Epoch 170/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8907 - loss: 0.4232\n",
            "Epoch 171/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8903 - loss: 0.4534\n",
            "Epoch 172/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8858 - loss: 0.4508\n",
            "Epoch 173/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8919 - loss: 0.4309\n",
            "Epoch 174/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.4730\n",
            "Epoch 175/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8788 - loss: 0.4483\n",
            "Epoch 176/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8788 - loss: 0.4382\n",
            "Epoch 177/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8974 - loss: 0.4229\n",
            "Epoch 178/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8956 - loss: 0.4033\n",
            "Epoch 179/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9014 - loss: 0.3995\n",
            "Epoch 180/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8729 - loss: 0.4339\n",
            "Epoch 181/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.4117\n",
            "Epoch 182/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8857 - loss: 0.4108\n",
            "Epoch 183/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - loss: 0.3843\n",
            "Epoch 184/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8940 - loss: 0.4000\n",
            "Epoch 185/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9020 - loss: 0.3682\n",
            "Epoch 186/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9021 - loss: 0.3847\n",
            "Epoch 187/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8907 - loss: 0.3847\n",
            "Epoch 188/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8808 - loss: 0.4061\n",
            "Epoch 189/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.4052\n",
            "Epoch 190/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.4137\n",
            "Epoch 191/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3838\n",
            "Epoch 192/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8981 - loss: 0.3814\n",
            "Epoch 193/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8949 - loss: 0.3974\n",
            "Epoch 194/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9071 - loss: 0.3505\n",
            "Epoch 195/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8894 - loss: 0.3990\n",
            "Epoch 196/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8918 - loss: 0.3933\n",
            "Epoch 197/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8928 - loss: 0.3824\n",
            "Epoch 198/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8882 - loss: 0.3807\n",
            "Epoch 199/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8948 - loss: 0.3727\n",
            "Epoch 200/200\n",
            "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8991 - loss: 0.3557\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aeSNfS7uhch0",
        "outputId": "5e8dc3fb-005e-4ac6-ac0b-41439ad0ba2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DC7zfcgviDTp",
        "outputId": "de9f7412-7896-4ec8-be95-f0848673b82e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "road to data scientist be dumb be dumb be dumb dumb dumb dumb dumb dumb dumb dumb dumb so you throwing time for hope hope came question hand as as as as care you\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"road to data scientist\"\n",
        "next_words = 30\n",
        "\n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c03_nlp_constructing_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}